# Benchmark Design: Validating Claude Learner Plugin

## Goal

Measure whether skills generated by `/learn` improve Claude's performance on unfamiliar real-world tasks.

## Approach

**A/B test with isolated environments:**
- **Control**: Fresh project directory, no learned skills
- **Treatment**: Fresh project directory with `/learn rust axum --project` skills

**Topic choice**: Rust + Axum (challenging/unfamiliar framework)

**Task**: "Build a REST API with Axum and SQLx that supports CRUD operations for a 'todos' resource"

## --project Flag Implementation

Add flag to `/learn` command for project-local skill generation:

```yaml
arguments:
  - name: topic
    required: true
  - name: project
    description: Generate skills in current project instead of ~/.claude/skills/
    required: false
    type: boolean
```

**Output location logic:**
- If `--project`: `./.claude/skills/{{topic-slug}}-{{subtopic}}/SKILL.md`
- Otherwise: `~/.claude/skills/{{topic-slug}}-{{subtopic}}/SKILL.md`

**Directory structure:**
```
/tmp/benchmark/
├── control/          # No learned skills
└── treatment/        # Has learned skills
    └── .claude/
        └── skills/
            ├── rust-axum-routing/
            ├── rust-axum-handlers/
            └── ...
```

## Execution Steps

### Phase 1: Setup

1. Create benchmark directories:
   ```bash
   mkdir -p /tmp/benchmark/{control,treatment}
   ```

2. In treatment directory, run:
   ```bash
   cd /tmp/benchmark/treatment
   /learn rust axum --project
   ```

3. Control directory stays empty

### Phase 2: Execute Tasks

Run identical task in both directories:

```
Task prompt:
"Build a REST API using Rust with Axum framework and SQLx for database access.
Requirements:
- Create a 'todos' resource with CRUD operations (Create, Read, Update, Delete)
- Use SQLite for the database
- Include proper error handling
- The API should compile and run

Start by initializing a new Rust project with cargo."
```

### Phase 3: Collect Metrics

For each run, capture:
- **Completion**: Compiles? Runs? Endpoints work?
- **Token usage**: Input + output tokens
- **Tool calls**: Count by type (Bash, Write, Edit, Read)
- **Time**: Wall clock duration
- **Errors**: Failed attempts, backtracking

## Data Collection

**Log format:**
```json
{
  "variant": "control | treatment",
  "task": "rust-axum-crud",
  "started_at": "ISO timestamp",
  "completed_at": "ISO timestamp",
  "tokens": { "input": 0, "output": 0 },
  "tool_calls": { "Bash": 0, "Write": 0, "Edit": 0, "Read": 0 },
  "completion": {
    "compiles": false,
    "runs": false,
    "endpoints_work": false,
    "all_crud_operations": false
  },
  "errors": [],
  "notes": ""
}
```

## Success Criteria

The benchmark validates the plugin if treatment shows improvement in ANY of:
- Higher completion rate
- Fewer tool calls for same outcome
- Fewer errors/backtracking
- More idiomatic code patterns

## Deliverable

Markdown report with:
1. Raw metrics comparison table
2. Qualitative observations
3. Conclusion: Did learned skills help?
